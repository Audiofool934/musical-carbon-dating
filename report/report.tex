
\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{hyperref}
\usepackage[numbers]{natbib}
\usepackage{xcolor}

\geometry{a4paper, margin=1in}
\graphicspath{{../output/figures/}}

\title{\textbf{Musical Carbon Dating}\\ \large A Statistical Feature Recognition Approach to Dating Audio (1960-2020)}
\author{Group Project}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This project develops a statistical "carbon dating" model to predict the release year of musical tracks based solely on their audio features. Analyzing a dataset of over 250,000 songs from 1960 to 2020, we treat year prediction as a feature recognition task. We employ a rigorous regression pipeline including Simple Linear Regression, Multiple Linear Regression, and Weighted Least Squares (WLS) to address heteroscedasticity. Our best model (WLS) achieves a statistically valid weighted $R^2=0.275$, reflecting the high variance of musical evolution, with a Mean Absolute Error (MAE) of approximately 9.30 years. Furthermore, we define a "Nostalgia Index" based on prediction residuals to quantify the "timelessness" or "retro" character of modern productions, validating this metric against known retro-style hits.
\end{abstract}

\section{Introduction}
In archaeology, scientists use Carbon-14 isotopes to date organic matter. In this study, we ask: Can we carbon-date culture? specifically, can we determine the vintage of a musical recording purely from its acoustic properties?

Music production has evolved significantly over the last six decades, driven by both technological innovation (analog to digital) and shifting cultural tastes. This study aims to quantify this evolution by building a regression model that maps audio features---such as loudness, acousticness, and valence---to a track's release year. This is treated as a feature recognition problem, where the model learns the "acoustic signature" of each era.

\section{Data and Methodology}
We analyzed the \textit{Spotify 600k Tracks Dataset} \citep{ay2021spotify}, applying filtering to ensure data quality:
\begin{itemize}
    \item \textbf{Time Range}: 1960--2020.
    \item \textbf{Popularity Filter}: Popularity $> 30$ to focus on culturally relevant music (N = 250,971 tracks).
    \item \textbf{Validation Strategy}: We use a \textbf{Random Split} (80\% Training, 20\% Test) to evaluate the model's ability to recognize the era of any given song based on learned feature patterns.
    \item \textbf{Standardization}: Comparison between features with different scales (e.g., Loudness in dB vs. Valance in 0-1) can be biased. We applied \textbf{Z-Score Standardization} to all predictors ($x' = \frac{x - \mu}{\sigma}$) to ensure scale invariance and convergence stability.
\end{itemize}

\section{Regression Analysis}

\subsection{Phase I: The "Loudness War" (Simple Linear Regression)}
We first examined the relationship between $Year$ and $Loudness$. 
$$ Year_i = \beta_0 + \beta_1 Loudness_i + \varepsilon_i $$
Results confirmed the "Loudness War" phenomenon ($\beta_1 \approx 4.98$, $t=159.4$), indicating a consistent increase in volume over decades. However, the low $R^2$ (0.130) suggests loudness alone is a weak predictor.

\subsection{Phase II: Multiple Linear Regression (MLR)}
Incorporating all 13 audio features (including energy, acousticness, valence, etc.) significantly improved predictive power.
$$ \mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon} $$
The OLS baseline achieved an $R^2$ of \textbf{0.238} with an RMSE of approximately 12.05 years. While an improvement, the model still left 76\% of the variance unexplained, prompting a rigorous diagnostic audit.

\subsection{Phase III: Diagnostic Audit}
We performed a comprehensive check of the Gauss-Markov assumptions to identify sources of error.

\subsubsection{A. Linearity \& Multicollinearity}
\begin{itemize}
    \item \textbf{Linearity}: We conducted a Partial F-Test by adding squared terms (e.g., $Duration^2$). The significant F-statistic ($F \approx 304.7$) confirmed non-linear evolution in song structures.
    \item \textbf{Multicollinearity}: Variance Inflation Factor (VIF) analysis showed generally low multicollinearity (VIF $< 4.0$ for all features), despite a moderate correlation between Loudness and Energy ($r=0.74$). This confirms that our features provide distinct information.
\end{itemize}

\subsubsection{B. Normality of Residuals}
The Q-Q plot revealed heavy tails (High Kurtosis), deviating from the normal distribution.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{residuals_mlr_residuals.png}
    \caption{Residual Diagnostics. Note the heavy tails in the Q-Q plot and "boundedness" artifacts in Residuals vs Fitted.}
    \label{fig:residuals}
\end{figure}
We interpret this not as model failure, but as \textbf{Stylistic Heterogeneity}---the existence of "retro" and "futuristic" tracks that naturally defy their era's trends.

\subsubsection{C. Heteroscedasticity}
The most critical violation was \textbf{Heteroscedasticity} (non-constant variance). The Breusch-Pagan test yielded a massive statistic ($\chi^2 \approx 19,567, p < 0.001$). Variance is clearly time-dependent, likely due to the diversification of genres in later decades.

\subsection{Phase IV: Model Refinement (WLS)}
To correct for heteroscedasticity, we implemented \textbf{Weighted Least Squares (WLS)}. Weights were inversely proportional to the variance of residuals ($w_i \propto 1/\sigma_i^2$).

\textbf{Important Clarification}: WLS does not improve prediction accuracy---it ensures \textbf{valid statistical inference}. Specifically:
\begin{itemize}
    \item \textbf{Coefficient estimates} remain unbiased but become \textit{efficient}.
    \item \textbf{Standard errors} are now correct, making p-values and confidence intervals trustworthy.
    \item The \textbf{Weighted $R^2 = 0.275$} measures how well the model captures core musical trends in the training data, correctly accounting for the high variance in specific eras.
\end{itemize}

\subsection{Phase V: Model Selection}
To ensure parsimony, we compared two selection methods:
\begin{itemize}
    \item \textbf{Stepwise Regression (AIC)}: Selected 12 features, dropping \texttt{key}.
    \item \textbf{LASSO ($L_1$ Regularization)}: Selected all 13 features.
\end{itemize}
We retained the full feature set as removing variables offered negligible AIC improvement.

\subsection{Phase VI: Musicological Interpretation ("From Diagnostics to Discovery")}
WLS provides \textbf{valid coefficient estimates}, allowing us to statistically confirm historical trends. By interpreting the \textbf{Partial Regression Coefficients} (holding other variables constant), we uncovered insights that simple correlation would miss:

\subsubsection{A. Technological Drivers ("The Sound of Efficiency")}
\begin{itemize}
    \item \textbf{The Loudness-Energy Paradox}: While modern music is louder, the coefficient for \texttt{energy} (controlling for loudness) is negative ($\beta \approx -1.20$). This supports the "Loudness War" theory: tracks are technically louder due to compression, but compositionally less energetic.
    \item \textbf{The Attention Economy}: The negative coefficient for \texttt{duration} ($\beta \approx -0.89$) confirms that the "skip rate" era is driving songs to become shorter.
\end{itemize}

\subsubsection{B. Cultural Evolution ("The Mood of an Era")}
\begin{itemize}
    \item \textbf{The Rise of Rhythm}: \texttt{Danceability} ($\beta \approx +3.86$) is the strongest predictor of modernity.
    \item \textbf{The Sad Banger Hypothesis}: The decline in \texttt{valence} ($\beta \approx -4.14$) is statistically significant ($p < 0.001$), confirming that modern pop is acoustically "darker".
    \item \textbf{The Acousticness Paradox}: Raw correlation ($r \approx -0.12$) suggests acousticness faded. However, the WLS coefficient is \textbf{positive} ($\beta \approx +0.62$). \textit{Ceteris Paribus}, controlling for the "Wall of Sound" (Loudness), modern genres (Indie, Lo-Fi) actually retain significant acoustic texturing.
\end{itemize}

\section{Applications: The Nostalgia Index}
While the model captures musical evolution (Weighted $R^2 = 0.275$), practical prediction accuracy is characterized by \textbf{MAE $\approx$ 9.30 years} on the test set. Large prediction errors are often informative. We define the \textbf{Nostalgia Index} as:
$$ \text{Nostalgia Index} = | \hat{y}_{pred} - y_{actual} | $$
A high index indicates a song that sounds significantly "out of time".

\textbf{Validation}:
Table \ref{tab:retro} demonstrates the index correctly identifying songs known for their retro aesthetic.

\begin{table}[htbp]
    \centering
    \begin{tabular}{llccc}
        \toprule
        \textbf{Song} & \textbf{Artist} & \textbf{Actual} & \textbf{Predicted} & \textbf{Index ($\Delta$ years)} \\ 
        \midrule
        Uptown Funk & Mark Ronson & 2015 & 2013.1 & 1.9 (Low) \\
        Physical & Dua Lipa & 2020 & 2009.0 & 11.0 (High) \\
        \bottomrule
    \end{tabular}
    \caption{Nostalgia Index examples. A higher index implies stronger displacement from the era's norms.}
    \label{tab:retro}
\end{table}

\section{Conclusion}
This study demonstrates that Regression Analysis is a powerful tool not just for prediction, but for \textbf{historical discovery}. Our rigorous application of diagnostics led us from a flawed OLS model to a robust Weighted Least Squares framework.

By prioritizing statistical validity (via WLS) over raw prediction, we successfully:
\begin{enumerate}
    \item \textbf{Quantified Cultural Shifts}: We proved the "Sad Banger" hypothesis (significant decline in Valence) and the "Rise of Rhythm" (dominant Danceability).
    \item \textbf{Identified Anomalies}: The Nostalgia Index turns the model's inability to predict outliers into a feature, successfully flagging retro-aesthetic tracks like \textit{Physical}.
    \item \textbf{Feasible Dating}: Achieved a practical dating accuracy of $\pm 9$ years (MAE).
\end{enumerate}

Ultimately, rigorous regression diagnostics allowed us to distinguish between statistical noise and meaningful cultural evolution.

\begin{thebibliography}{9}
\bibitem{ay2021spotify}
Yamac Eren Ay. (2021). \textit{Spotify Dataset 1921-2020, 600k+ Tracks}. Kaggle. \url{https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-1921-2020-600k-tracks}
\end{thebibliography}

\end{document}
